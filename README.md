# üëã Hi, I'm Tatiana ‚Äî Data & AI Integration Specialist

I work with data quality, AI data operations, Python automation, and API integrations.  
My background combines AI annotation, data validation, workflow automation, and system logic.  
This portfolio includes my practical projects in Python, automation, and AI data workflows.

---

## üöÄ Featured Projects

### 1Ô∏è‚É£ Data Quality Dashboard for Customer Claims
**Tools:** Excel, CRM, internal reporting systems  
Analyzed customer claims, categorized defect types, tracked resolution times, and created a dashboard to identify recurring issues and improve processes.

‚û°Ô∏è *LinkedIn project section*

---

### 2Ô∏è‚É£ Workflow Automation using n8n
**Tools:** n8n, webhooks, email integration  
Built an automated workflow to collect, validate, and store structured data. Added notifications for inconsistent entries and documented the workflow logic.

‚û°Ô∏è *LinkedIn project section*

---

### 3Ô∏è‚É£ Search Relevance Evaluation Framework
**Tools:** internal annotation tools  
Created structured guidelines for evaluating search relevance, defined criteria for quality levels, and improved annotation consistency for AI search models.

‚û°Ô∏è *LinkedIn project section*

---

### 4Ô∏è‚É£ Python Script for Data Cleaning & Validation
**Tools:** Python, Pandas  
A script that checks CSV files for missing values, duplicates, incorrect formats, and inconsistent entries, then generates a cleaned dataset.

```python
import pandas as pd

df = pd.read_csv("data.csv")

missing = df.isnull().sum()
duplicates = df.duplicated().sum()

numeric_like_strings = (
    df.select_dtypes(include="object")
      .apply(lambda x: x.str.match(r"^\d+(\.\d+)?$").sum())
)

print("=== Data Quality Report ===")
print("Missing values:\n", missing)
print("\nDuplicate rows:", duplicates)
print("\nNumeric-like strings in object columns:\n", numeric_like_strings)

df_cleaned = df.drop_duplicates()
df_cleaned = df_cleaned.fillna("N/A")

df_cleaned.to_csv("cleaned_data.csv", index=False)
print("\nCleaned file saved as cleaned_data.csv")
–û—Ç–ª–∏—á–Ω–æ, –¢–∞—Ç—å—è–Ω–∞ ‚Äî —Å–µ–π—á–∞—Å –º—ã —Å–æ–∑–¥–∞–¥–∏–º **–ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—É—é –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ‚Äë—Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–∞ GitHub**, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å –∫–∞–∫ –º–∏–Ω–∏‚Äë—Å–∞–π—Ç –∏ —Å—Ç–∞–Ω–µ—Ç —Ç–≤–æ–µ–π –≤–∏–∑–∏—Ç–∫–æ–π –¥–ª—è —Ä–µ–∫—Ä—É—Ç–µ—Ä–æ–≤.  
–°–¥–µ–ª–∞–µ–º –≤—Å—ë **–ø–æ—à–∞–≥–æ–≤–æ, –∫–∞–∫ LEGO**, –±–µ–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–µ–π, –±–µ–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤.

–¢—ã –ø–æ–ª—É—á–∏—à—å:

- –≥–æ—Ç–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É  
- –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç  
- –≥–æ—Ç–æ–≤—ã–π README  
- –≥–æ—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–æ–≤  
- –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∫—É–¥–∞ –Ω–∞–∂–∞—Ç—å –∏ —á—Ç–æ –≤—Å—Ç–∞–≤–∏—Ç—å  

–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ —É —Ç–µ–±—è –±—É–¥–µ—Ç **–∫—Ä–∞—Å–∏–≤–æ–µ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ**, –∫–æ—Ç–æ—Ä–æ–µ –º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Ä–µ–∫—Ä—É—Ç—ë—Ä–∞–º –∏ –¥–æ–±–∞–≤–ª—è—Ç—å –≤ LinkedIn.

---

# ‚≠ê –ß–¢–û –ú–´ –°–ï–ô–ß–ê–° –î–ï–õ–ê–ï–ú

–ú—ã —Å–æ–∑–¥–∞—ë–º:

### üëâ GitHub Portfolio Page  
–≠—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞, –∫–æ—Ç–æ—Ä–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ—è–≤–ª—è–µ—Ç—Å—è, –µ—Å–ª–∏ —Ç—ã —Å–æ–∑–¥–∞—ë—à—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º:

**`yourusername/yourusername`**

–ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ —Ç–≤–æ–π GitHub ‚Äî `tatiana-ai`, —Ç–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–æ–ª–∂–µ–Ω –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è:

**`tatiana-ai/tatiana-ai`**

–í–Ω—É—Ç—Ä–∏ –±—É–¥–µ—Ç —Ñ–∞–π–ª **README.md** ‚Äî —ç—Ç–æ –∏ –µ—Å—Ç—å —Ç–≤–æ—è –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ‚Äë—Å—Ç—Ä–∞–Ω–∏—Ü–∞.

---

# ‚≠ê –®–ê–ì 1. –°–æ–∑–¥–∞—ë–º GitHub‚Äë—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ

1. –ó–∞–π–¥–∏ –Ω–∞ GitHub.  
2. –ù–∞–∂–º–∏ **New repository**.  
3. –í –ø–æ–ª–µ **Repository name** –Ω–∞–ø–∏—à–∏ **—Ç–æ—á–Ω–æ —Å–≤–æ—ë –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è**.  
   –ü—Ä–∏–º–µ—Ä:  
   –µ—Å–ª–∏ —Ç–≤–æ–π GitHub ‚Äî `tatiana-ai`, —Ç–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–æ–ª–∂–µ–Ω –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è:  
   **`tatiana-ai`**  
4. –ü–æ—Å—Ç–∞–≤—å –≥–∞–ª–æ—á–∫—É **‚ÄúAdd a README file‚Äù**.  
5. –ù–∞–∂–º–∏ **Create repository**.

–ì–æ—Ç–æ–≤–æ ‚Äî —É —Ç–µ–±—è –ø–æ—è–≤–∏–ª–∞—Å—å –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ‚Äë—Å—Ç—Ä–∞–Ω–∏—Ü–∞.

---

# ‚≠ê –®–ê–ì 2. –û—Ç–∫—Ä—ã–≤–∞–µ–º README.md

1. –í–Ω—É—Ç—Ä–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –Ω–∞–∂–º–∏ –Ω–∞ —Ñ–∞–π–ª **README.md**.  
2. –ù–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É **Edit** (–∫–∞—Ä–∞–Ω–¥–∞—à–∏–∫).  
3. –£–¥–∞–ª–∏ –≤—Å—ë, —á—Ç–æ —Ç–∞–º –µ—Å—Ç—å.  
4. –í—Å—Ç–∞–≤—å —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π —è –¥–∞–º –Ω–∏–∂–µ.

---

# ‚≠ê –®–ê–ì 3. –í—Å—Ç–∞–≤–ª—è–µ–º –≥–æ—Ç–æ–≤—ã–π README (–ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ)

–°–∫–æ–ø–∏—Ä—É–π –∏ –≤—Å—Ç–∞–≤—å –ø–æ–ª–Ω–æ—Å—Ç—å—é:

```
# üëã Hi, I'm Tatiana ‚Äî Data & AI Integration Specialist

I work with data quality, AI data operations, Python automation, and API integrations.  
My background combines AI annotation, data validation, workflow automation, and system logic.  
This portfolio includes my practical projects in Python, automation, and AI data workflows.

---

## üöÄ Featured Projects

### 1Ô∏è‚É£ Data Quality Dashboard for Customer Claims
**Tools:** Excel, CRM, internal reporting systems  
Analyzed customer claims, categorized defect types, tracked resolution times, and created a dashboard to identify recurring issues and improve processes.

‚û°Ô∏è *LinkedIn project section*

---

### 2Ô∏è‚É£ Workflow Automation using n8n
**Tools:** n8n, webhooks, email integration  
Built an automated workflow to collect, validate, and store structured data. Added notifications for inconsistent entries and documented the workflow logic.

‚û°Ô∏è *LinkedIn project section*

---

### 3Ô∏è‚É£ Search Relevance Evaluation Framework
**Tools:** internal annotation tools  
Created structured guidelines for evaluating search relevance, defined criteria for quality levels, and improved annotation consistency for AI search models.

‚û°Ô∏è *LinkedIn project section*

---

### 4Ô∏è‚É£ Python Script for Data Cleaning & Validation
**Tools:** Python, Pandas  
A script that checks CSV files for missing values, duplicates, incorrect formats, and inconsistent entries, then generates a cleaned dataset.

```python
import pandas as pd

df = pd.read_csv("data.csv")

missing = df.isnull().sum()
duplicates = df.duplicated().sum()

numeric_like_strings = (
    df.select_dtypes(include="object")
      .apply(lambda x: x.str.match(r"^\d+(\.\d+)?$").sum())
)

print("=== Data Quality Report ===")
print("Missing values:\n", missing)
print("\nDuplicate rows:", duplicates)
print("\nNumeric-like strings in object columns:\n", numeric_like_strings)

df_cleaned = df.drop_duplicates()
df_cleaned = df_cleaned.fillna("N/A")

df_cleaned.to_csv("cleaned_data.csv", index=False)
print("\nCleaned file saved as cleaned_data.csv")
```

---

### 5Ô∏è‚É£ API Integration: Fetching and Validating Public Data
**Tools:** Python, Requests, Pandas  
A script that retrieves JSON from a public REST API, validates required fields and types, and saves clean data into a CSV file.

```python
import requests
import pandas as pd

url = "https://jsonplaceholder.typicode.com/posts"

response = requests.get(url)
response.raise_for_status()

data = response.json()

required_fields = ["userId", "id", "title", "body"]
validated_data = []

for item in data:
    if all(field in item for field in required_fields):
        if (
            isinstance(item["userId"], int)
            and isinstance(item["id"], int)
            and isinstance(item["title"], str)
            and isinstance(item["body"], str)
        ):
            validated_data.append(item)

df = pd.DataFrame(validated_data)
df.to_csv("api_posts_cleaned.csv", index=False)

print(f"Saved {len(df)} valid records to api_posts_cleaned.csv")
```

---

## üß∞ Skills

- Data Annotation & Data Quality  
- Python (Pandas, Requests)  
- API Integration  
- Automation (n8n)  
- Data Validation  
- Process Optimization  
- Computer Vision & Speech Data  
- CRM / ERP / POS systems  

---

## üåç Languages
- Russian ‚Äî Native  
- English ‚Äî Professional  
- Spanish ‚Äî Professional  

---

## üì´ Contact
- LinkedIn: [*your link here*  ](https://www.linkedin.com/feed)
- Email: chumatv@gmail.com

---

Thanks for visiting my portfolio!
```
